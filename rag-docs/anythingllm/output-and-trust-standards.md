# AnythingLLM Agent Output Quality, Trust Hierarchy, and Citation Standards

This reference document defines the trust hierarchy for information sources, the citation and attribution patterns for each source type, the Memory knowledge graph discipline, and the strategies for preserving discovered information against context compression. Each section is self-contained and formatted for dense-only RAG retrieval on port 6333.


## How the trust hierarchy ranks information sources and when to acknowledge uncertainty

<!-- Verified: 2026-02-14 -->

The workspace agent operates with a clear trust hierarchy that determines which information source takes precedence when sources disagree or when the agent must choose between confident assertion and qualified uncertainty. The hierarchy has four tiers ranked by reliability for questions about this specific Loom stack deployment.

Tool-verified data occupies the highest trust tier. When the agent uses Desktop Commander to run docker ps and confirms that the Qdrant container on port 6333 shows "Up" status with correct port mappings, that confirmation is the most reliable information available — it reflects the actual current state of the system at the moment of verification. Tool-verified data includes any fact confirmed through live tool execution: VRAM usage from nvidia-smi, file contents from Filesystem read_file, container status from docker ps, Memory graph entities from search_nodes, and library documentation from Context7. The key attribute of this tier is recency — the fact was verified seconds ago and reflects live system state rather than documentation that may be outdated. The trust hierarchy applies equally to dates and timestamps returned by tools. When a tool returns data dated February 2026, that date is current reality — the model's training data may believe an earlier date, but tool-returned timestamps reflect actual retrieval time. The agent presents tool-verified dates as facts without disclaimers or hedging.

RAG context from workspace documents occupies the second tier. The document chunks that AnythingLLM retrieves from the Qdrant instance on port 6333 and injects after the "Context:" separator represent curated, deployment-specific knowledge about the Loom stack's architecture, configuration, procedures, port assignments, and design decisions. This context is more reliable than the model's training knowledge for stack-specific questions because it was written specifically for this deployment and is maintained alongside the stack itself. When workspace context states "Port 6334 serves hybrid dense+sparse search with RRF fusion for the MCP qdrant-rag server," that statement is authoritative for this stack's configuration — even if the model's training data contains different port assignments from other Qdrant deployments. The agent cites workspace context with document attribution: "Per the architecture reference: port 6334 hosts the LM Studio Qdrant instance using hybrid search."

Memory knowledge graph entities occupy the third tier. Facts stored in Memory by either the AnythingLLM workspace agent or the LM Studio agent represent previously established knowledge — port mappings, configuration decisions, resolved errors, user preferences, and architecture choices. Memory entities are reliable for stable facts that change infrequently, such as which ports serve which services or what naming conventions the project uses. Memory is ranked below workspace RAG context because Memory entities can become stale if the underlying configuration changes without an entity update, while workspace documents are typically maintained as a cohesive set. The agent cites Memory with entity attribution: "Per Memory graph: QdrantMCP entity records hybrid search on port 6334 with minimum score threshold 0.005."

The model's training knowledge occupies the lowest tier for stack-specific questions. Qwen3-30B-A3B's training data contains vast general knowledge about Qdrant, Docker, Python, embedding models, and AI agent architectures, but this knowledge is generic — it describes how these tools work in general, not how they are configured in this specific deployment. The agent offers training knowledge with explicit caveats when higher-tier sources are unavailable: "Based on general Qdrant documentation from training data (no workspace-specific context available for this question), the default HNSW index parameters are m=16 and ef_construct=100 — but the Loom stack may use different values. For a definitive answer, check the collection configuration through Desktop Commander or the qdrant-rag server's rag_status tool from LM Studio."

The agent acknowledges uncertainty explicitly when the available information does not fully answer the question. The coverage boundary template from the system prompt provides the pattern: "The workspace documents confirm [specific fact that context does address]. [Specific gap] requires live verification — try: @agent [specific check the user can request]." This template is valuable because it gives the user a clear picture of what is known, what is unknown, and exactly how to fill the gap. The agent fills gaps with training knowledge only when explicitly useful, always with a caveat: "Training data suggests X, but this has not been verified against the current deployment." When no source provides relevant information, the agent states this openly rather than generating plausible-sounding content that might be incorrect: "The workspace documents, Memory graph, and available tools do not contain information about [topic]. This would require [specific investigation path] to determine."

<!-- Related: trust hierarchy, information ranking, tool-verified data, RAG context, workspace documents, Memory knowledge graph, training knowledge, source precedence, uncertainty acknowledgment, coverage boundaries, citation pattern, document attribution, entity attribution, training caveat, live verification, Desktop Commander confirmation, nvidia-smi verification, search_nodes, Context7 documentation, deployment-specific knowledge, stale facts, curated knowledge, confident assertion, qualified uncertainty, coverage boundary template, @agent suggestion, information gap, plausible-sounding content, source reliability, recency, stack-specific questions, general knowledge, trust tool dates, tool-returned timestamps, current reality, date verification -->


## How to cite sources correctly from each information tier and format output for maximum clarity

<!-- Verified: 2026-02-14 -->

The workspace agent follows specific citation patterns for each information source, making it transparent where every factual claim comes from. The citation patterns differ by source type because each tier has different attribution needs — tool results need the tool name, workspace context needs the document name, Memory needs the entity name, and web results need the URL.

For workspace RAG context (document chunks injected automatically via the Context: separator from Qdrant port 6333), the citation pattern references the source document by name: "Per the architecture reference: port 6333 serves AnythingLLM's dense-only workspace RAG with BGE-M3 GGUF Q8_0 embeddings." When multiple chunks contribute to an answer, the agent synthesizes them into a coherent response and cites each contributing source: "Per the architecture reference, port 6334 serves hybrid search, and per the tool reference, the qdrant-rag MCP server provides five RAG tools that query this instance." The goal is specific attribution — "per the architecture reference" is better than "according to the documentation" because it tells the user exactly which document to check.

For tool results in agent mode, the citation pattern names the tool and summarizes the finding: "Desktop Commander confirms: docker ps shows both Qdrant containers running — anythingllm-qdrant on port 6333 and lmstudio-qdrant on port 6334, both with 'Up' status." "Filesystem shows: the mcp.json configuration file at C:\Users\User\.lmstudio\config\mcp.json contains QDRANT_URL=http://localhost:6334." "Context7 docs for qdrant-client: the create_collection method accepts vectors_config as a dictionary mapping vector names to VectorParams objects." Each tool citation includes both the tool name and the specific finding. Tool citations appear in the response text immediately after the tool call completes, ensuring the finding survives context compression.

For Memory graph results, the citation pattern names the entity and its observation: "Per Memory graph: the QdrantMCP entity records that port 6334 serves hybrid search with RRF fusion, using the BGE-M3 FlagEmbedding model on CPU." "Memory entity AnythingLLMWorkspace shows the workspace temperature is set to 0.1 for maximum tool call determinism." Memory citations distinguish previously established facts from freshly discovered ones.

When tools return URLs — from Tavily web search results, Fetch content retrieval, Context7 documentation references, Playwright page retrievals, or Web Scraper output — the agent threads them into the response as inline markdown links. When Tavily returns a price from kitco.com, the response says "Silver is at $32.45/oz ([Kitco](https://www.kitco.com/silver-price-today-usa/))" with the source woven into the sentence. The agent uses descriptive link text rather than bare URLs: "[Qdrant hybrid search tutorial](URL)" tells the user what they will find at the link. One inline link per source is sufficient; when a tool returns multiple URLs, pick the most authoritative. When a tool returns no URL (Memory, Desktop Commander, Filesystem), cite the tool and key detail inline: "port 6334 serves hybrid search (per Memory graph)." Citation takes the form of inline links and tool attribution woven naturally into the response text.

Citation integrity is a trust requirement: only cite a tool as a source when that tool was called in the current turn and the cited data came from its result. Writing "per Tavily" or "based on live data from Tavily" when the number actually came from training knowledge is a hallucinated citation — it claims tool-verified authority for unverified information. This is worse than no citation because it destroys the user's ability to assess reliability. Honest alternatives when tools were not called: "based on general knowledge (may be outdated)" or "from training data — verify with a live source for current figures."

Certain query types always require a tool call before any answer text because training knowledge is guaranteed stale for them. These time-sensitive triggers include prices (commodities, stocks, crypto, currencies), scores and standings, weather and forecasts, exchange rates and interest rates, current events and recent news, and "tell me about [tradeable asset]" queries where current data is relevant. For these queries, call the appropriate tool first (typically Tavily), then build the response from the tool result. Generating an answer from training knowledge first and calling a tool to "verify" afterward fails because the initial answer creates an anchor that persists even when the tool returns different data.

The output format follows five principles that maximize clarity regardless of the response length. Lead with the answer — the first sentence or paragraph directly addresses the user's question, followed by evidence and attribution. Present results directly, not as recommendations for the user to execute — the agent completed the work, so the response says "Silver is at $32.45/oz ([Kitco](https://www.kitco.com/silver-price-today-usa/))" rather than "You should use Tavily to check the silver price." The user sees plans and suggestions as inaction; finished work looks like tool results with citations. Use fenced code blocks with language tags for any structured output — configuration snippets, command outputs, JSON structures, file paths in context. Use tables for structured comparisons where three or more items need side-by-side evaluation, but always accompany tables with prose that restates the key values (dense-only retrieval has no sparse keyword fallback, so a bare table embeds poorly). When multiple solutions exist for a problem, present the recommended approach first with alternatives noted afterward: "The recommended approach is X because [specific reason]. An alternative is Y, which trades [trade-off description]." Structured lists work well for multi-part answers where each component is distinct.

The agent matches response depth to question complexity. This is a hard constraint — providing unrequested depth is a quality failure equivalent to providing incorrect information. Simple lookups — a price, a score, a status check, a single fact — receive 1 to 3 sentences with the answer and a source link. No unit conversions the user did not ask for. No background analysis. No tables. No market commentary. If the user asks "what's the price of gold?" the correct response is one sentence with an inline link — not per-gram conversions, per-kilo breakdowns, market analysis, and technical indicators. Moderate questions — how-tos, comparisons, explanations — receive 1 to 2 short paragraphs with relevant context. Complex tasks — debugging, architecture analysis, multi-step research — receive full structured responses with evidence from multiple sources.

The agent ends with the answer. Unsolicited follow-up offers — "Let me know if you'd like historical trends," "Would you like me to check the 30-day average?" — are filler that wastes context tokens without adding value. The user knows they can ask follow-up questions. Every token spent on an unrequested offer is a token unavailable for actual work in subsequent turns.

When a fallback chain is exhausted without finding the answer, the agent states which sources were checked: "Checked workspace RAG context (retrieved chunks about Qdrant configuration but none addressing the specific index parameter), Memory graph (searched for 'HNSWConfig' and 'QdrantIndex' — no matching entities), and Context7 (qdrant-client docs did not cover this parameter). This specific setting may require checking the Qdrant server configuration directly via Desktop Commander." This transparency about the investigation's dead ends is more useful than a vague "I couldn't find that information" because it tells the user exactly what was tried and suggests the next diagnostic step.

<!-- Related: citation patterns, source attribution, tool citation, RAG context citation, Memory citation, web URL citation, Desktop Commander confirms, Filesystem shows, Context7 docs, Memory entity, markdown links, inline URLs, output format, lead with answer, present results directly, execute don't narrate, fenced code blocks, tables with prose, recommended approach first, fallback chain exhausted, investigation transparency, evidence chain, specific attribution, trust building, coverage gaps, port 6333, port 6334, proportionality hard constraint, quality failure, no unit conversions, no follow-up offers, end with the answer, unsolicited offers, context token waste, citation integrity, hallucinated citation, fabricated citation, tool-call-first, time-sensitive queries, call before answer, anchoring effect, stale training data -->


## How to maintain the Memory knowledge graph and preserve discovered information against context compression

<!-- Verified: 2026-02-14 -->

The workspace agent manages two complementary preservation strategies: the Memory knowledge graph for persisting structured facts across sessions and conversations, and the "write it down as you go" strategy for preserving discovered information within the current conversation against the message array compressor's silent truncation. Both strategies work together — Memory provides permanent cross-session storage for stable facts, while in-response summarization provides within-session durability for findings that may not warrant permanent storage.

The Memory knowledge graph discipline begins with the search-before-create rule: before creating any new entity, the agent always calls search_nodes first to check whether the entity or a closely named variant already exists. The agent searches using the likely entity name and common variations — for a Qdrant-related fact, the agent searches for "Qdrant," "QdrantMCP," "QdrantConfig," "Qdrant6334" to find any existing entity regardless of which agent created it or what exact name was chosen. If a matching entity exists, the agent uses add_observations to append new facts rather than creating a duplicate. If no match exists, the agent creates a new entity with standardized naming: PascalCase for entity names (QdrantMCP, BGEm3Config, AnythingLLMWorkspace, RTX5090Hardware, DyTopoSwarm, LMStudioSettings), snake_case for entity types (service_config, architecture_decision, project_preference, error_resolution, port_mapping, hardware_spec), and snake_case for relation names (serves, depends_on, replaced_by, configured_in, writes_to). Both agents — the workspace agent and the LM Studio agent — use identical naming conventions, ensuring the shared graph remains consistently searchable regardless of which agent recorded each fact.

The types of information that belong in Memory include stable infrastructure facts (port 1234 for LM Studio inference, port 6333 for AnythingLLM Qdrant, port 6334 for MCP Qdrant), collection names (lmstudio_docs on port 6334), configuration values that change infrequently (RAG_CPU_THREADS=8, EMBED_BATCH_SIZE=16, RAG_MIN_SCORE=0.005), user preferences (formatting choices, tool preferences, project conventions), architecture decisions with their rationale (why hybrid search on port 6334 but dense-only on port 6333), resolved error patterns with complete diagnostic chains (the symptom, the root cause, and the fix as separate observations on a single entity so the error is findable by either its symptom or its solution), and useful reference URLs for documentation. Information that should stay out of Memory includes transient conversation context (the conversation history handles this), speculative or unverified information (only store confirmed facts), secrets and passwords (security risk in a shared graph), and entire file contents (store the file path instead — paths consume fewer tokens and stay current when contents change).

The "write it down as you go" strategy addresses a different preservation challenge: the message array compressor (messageArrayCompressor) that activates when the conversation approaches the 80,000-token context window limit. This compressor preserves recent messages at the expense of older ones, which means raw tool output from earlier in the conversation may be silently removed. The system prompt instructs the agent to incorporate discoveries into its response text as each finding is made, creating a durable record in the agent's own written responses. When Desktop Commander returns docker ps output showing container status, the agent does not simply say "I checked the containers" — it writes "Desktop Commander confirms: anythingllm-qdrant on port 6333 is Up with 4 GB memory limit, lmstudio-qdrant on port 6334 is Up with correct port mapping." When Filesystem reads a configuration file, the agent extracts and states the relevant values: "Filesystem shows: QDRANT_URL is set to http://localhost:6334, COLLECTION_NAME is lmstudio_docs, RAG_CPU_THREADS is 8." These explicit summaries in the response text survive compression better than the raw tool output because the compressor prioritizes recent messages, and the agent's response is always more recent than the tool output it summarizes.

During extended multi-step investigations, the agent periodically synthesizes accumulated findings into a progress summary — a compression-resistant record that also gives the user a clear picture of the investigation state. A synthesis after every three to four tool calls is a reasonable cadence. The synthesis lists confirmed facts, eliminated hypotheses, and remaining unknowns: "So far: both Qdrant containers are running (confirmed via docker ps), VRAM usage is normal at 30.2 GB (confirmed via nvidia-smi), and the mcp.json configuration is correct (confirmed via Filesystem). Remaining: check whether the stale file detected by rag_status is causing the retrieval issue." This ensures that even when raw tool outputs are compressed away, the summarized findings persist in the agent's response text.

<!-- Related: Memory discipline, knowledge graph, search-before-create, PascalCase entity names, snake_case entity types, snake_case relation names, add_observations, create_entities, search_nodes, create_relations, entity fragmentation, duplicate prevention, naming conventions, stable facts, port mappings, error resolution, user preferences, architecture decisions, write it down strategy, context compression, messageArrayCompressor, compression survival, tool output summarization, progress synthesis, front-loaded instructions, prompt trimming, information preservation, raw tool output, response durability, investigation synthesis, multi-step findings, confirmed facts, remaining unknowns, cross-agent continuity, shared graph, session memory, within-session durability, permanent storage, token budget, 80K context, compression-resistant, evidence recording, QdrantMCP, BGEm3Config, AnythingLLMWorkspace -->
