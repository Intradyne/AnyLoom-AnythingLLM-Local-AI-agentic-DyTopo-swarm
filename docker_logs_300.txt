[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m Attached document-summarizer plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m Attached web-scraping plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m Attached asset-price (asset-price) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m Attached smart-web-reader (smart-web-reader) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":3,"result":{"tools":[{"name":"fetch","description":"Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.","inputSchema":{"description":"Parameters for fetching a URL.","properties":{"url":{"description":"URL to fetch","format":"uri","minLength":1,"title":"Url","type":"string"},"max_length":{"default":5000,"description":"Maximum number of characters to return.","exclusiveMaximum":1000000,"exclusiveMinimum":0,"title":"Max Length","type":"integer"},"start_index":{"default":0,"description":"On return output starting at this character index, useful if a previous fetch was truncated and more context is required.","minimum":0,"title":"Start Index","type":"integer"},"raw":{"default":false,"description":"Get the actual HTML content of the requested page, without simplification.","title":"Raw","type":"boolean"}},"required":["url"],"title":"Fetch","type":"object"}}]}}
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m Attached MCP::fetch:fetch MCP tool to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m [debug]: @agent is attempting to call `smart-web-reader` tool {
  "url": "https://example.com"
}
[36m[backend][0m [32minfo[39m: [36m[EphemeralAgentHandler][0m smart-web-reader: extraction via Defuddle succeeded
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call smart-web-reader again because an exact duplicate of previous run of smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: [32m[Event Logged][0m - api_sent_chat
[36m[backend][0m [32minfo[39m: [32m[Event Logged][0m - sent_chat
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Start 9f13e083-2319-4aea-98dd-ef10d4b95263::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached websocket plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached chat-history plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attaching user and default agent to Agent cluster.
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m MCP Servers already running, skipping boot.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached rag-memory plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached document-summarizer plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached web-scraping plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached asset-price (asset-price) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached smart-web-reader (smart-web-reader) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":4,"result":{"tools":[{"name":"fetch","description":"Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.","inputSchema":{"description":"Parameters for fetching a URL.","properties":{"url":{"description":"URL to fetch","format":"uri","minLength":1,"title":"Url","type":"string"},"max_length":{"default":5000,"description":"Maximum number of characters to return.","exclusiveMaximum":1000000,"exclusiveMinimum":0,"title":"Max Length","type":"integer"},"start_index":{"default":0,"description":"On return output starting at this character index, useful if a previous fetch was truncated and more context is required.","minimum":0,"title":"Start Index","type":"integer"},"raw":{"default":false,"description":"Get the actual HTML content of the requested page, without simplification.","title":"Raw","type":"boolean"}},"required":["url"],"title":"Fetch","type":"object"}}]}}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached MCP::fetch:fetch MCP tool to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "crypto museums or Bitcoin-related physical locations near Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "Bitcoin-related locations, crypto museums, or exhibits near Denver, Colorado, or within a 500-mile radius"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "Bitcoin-related locations or crypto museums within 500 miles of Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call rag-memory again because an exact duplicate of previous run of rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `smart-web-reader` tool {
  "url": "https://en.wikipedia.org/wiki/Large_language_model"
}
[36m[backend][0m [31merror[39m: Defuddle Error processing document: SyntaxError: ',* MathJax scripts and previews *,,	script[type^="math/"],.MathJax_Preview,,,* External math library scripts *,,	script[type="text/javascript"][src*="mathjax"],script[type="text/javascript"][src*="katex"]' is not a valid selector
    at emit (/app/server/node_modules/nwsapi/src/nwsapi.js:670:17)
    at parse (/app/server/node_modules/nwsapi/src/nwsapi.js:1612:13)
    at Object._querySelectorAll [as select] (/app/server/node_modules/nwsapi/src/nwsapi.js:1701:44)
    at HTMLParagraphElementImpl.querySelectorAll (/app/server/node_modules/jsdom/lib/jsdom/living/nodes/ParentNode-impl.js:80:26)
    at HTMLParagraphElement.querySelectorAll (/app/server/node_modules/jsdom/lib/jsdom/living/generated/Element.js:1119:58)
    at Object.transform (/app/server/node_modules/defuddle/dist/index.js:1:1096)
    at /app/server/node_modules/defuddle/dist/index.js:1:88844
    at Proxy.forEach (<anonymous>)
    at /app/server/node_modules/defuddle/dist/index.js:1:88805
    at Array.forEach (<anonymous>)
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m smart-web-reader: extraction via Defuddle succeeded
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running web-scraping.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `web-scraping` tool {
  "url": "https://en.wikipedia.org/wiki/List_of_cryptocurrency_museums_and_exhibits"
}
[36m[backend][0m [32minfo[39m: [36m[EncryptionManager][0m Loaded existing key & salt for encrypting arbitrary data.
[36m[collector][0m [32minfo[39m: -- Working URL https://en.wikipedia.org/wiki/List_of_cryptocurrency_museums_and_exhibits => (captureAs: text) --
[36m[collector][0m [31merror[39m: HTTP 404: Not Found
[36m[collector][0m [32minfo[39m: -- URL determined to be null (web) --
[36m[backend][0m [32minfo[39m: [35m[TokenManager][0m Returning existing instance for model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call smart-web-reader again because an exact duplicate of previous run of smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m End 9f13e083-2319-4aea-98dd-ef10d4b95263::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [32m[Event Logged][0m - sent_chat
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Start 2901ac79-e166-431b-bb10-49e57beac499::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached websocket plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached chat-history plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attaching user and default agent to Agent cluster.
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m MCP Servers already running, skipping boot.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached rag-memory plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached document-summarizer plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached web-scraping plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached asset-price (asset-price) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached smart-web-reader (smart-web-reader) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":5,"result":{"tools":[{"name":"fetch","description":"Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.","inputSchema":{"description":"Parameters for fetching a URL.","properties":{"url":{"description":"URL to fetch","format":"uri","minLength":1,"title":"Url","type":"string"},"max_length":{"default":5000,"description":"Maximum number of characters to return.","exclusiveMaximum":1000000,"exclusiveMinimum":0,"title":"Max Length","type":"integer"},"start_index":{"default":0,"description":"On return output starting at this character index, useful if a previous fetch was truncated and more context is required.","minimum":0,"title":"Start Index","type":"integer"},"raw":{"default":false,"description":"Get the actual HTML content of the requested page, without simplification.","title":"Raw","type":"boolean"}},"required":["url"],"title":"Fetch","type":"object"}}]}}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached MCP::fetch:fetch MCP tool to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `smart-web-reader` tool {
  "url": "https://en.wikipedia.org/wiki/Large_language_model"
}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m smart-web-reader: extraction via Defuddle succeeded
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: Client took too long to respond, chat thread is dead after 300000ms
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `smart-web-reader` tool {
  "url": "https://en.wikipedia.org/wiki/List_of_museums_in_the_United_States#Cryptocurrency_and_blockchain_museums"
}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m smart-web-reader: extraction via Defuddle succeeded
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "physical Bitcoin-related locations or crypto museums near Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call smart-web-reader again because an exact duplicate of previous run of smart-web-reader.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m End 2901ac79-e166-431b-bb10-49e57beac499::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [32m[Event Logged][0m - sent_chat
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Start 0a126e6d-3057-45d9-89dd-e84e65fa3d40::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached websocket plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached chat-history plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attaching user and default agent to Agent cluster.
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m MCP Servers already running, skipping boot.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached rag-memory plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached document-summarizer plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached web-scraping plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached asset-price (asset-price) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached smart-web-reader (smart-web-reader) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":6,"result":{"tools":[{"name":"fetch","description":"Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.","inputSchema":{"description":"Parameters for fetching a URL.","properties":{"url":{"description":"URL to fetch","format":"uri","minLength":1,"title":"Url","type":"string"},"max_length":{"default":5000,"description":"Maximum number of characters to return.","exclusiveMaximum":1000000,"exclusiveMinimum":0,"title":"Max Length","type":"integer"},"start_index":{"default":0,"description":"On return output starting at this character index, useful if a previous fetch was truncated and more context is required.","minimum":0,"title":"Start Index","type":"integer"},"raw":{"default":false,"description":"Get the actual HTML content of the requested page, without simplification.","title":"Raw","type":"boolean"}},"required":["url"],"title":"Fetch","type":"object"}}]}}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached MCP::fetch:fetch MCP tool to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "Bitcoin-related locations, crypto museums, or exhibits near Denver, Colorado, in February"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "Bitcoin-related locations or crypto museums near Denver, Colorado, in February"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "crypto museums or Bitcoin-related physical locations near Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "crypto museums, Bitcoin-related locations, or blockchain exhibits near Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call rag-memory again because an exact duplicate of previous run of rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: Client took too long to respond, chat thread is dead after 300000ms
[36m[backend][0m [32minfo[39m: Client took too long to respond, chat thread is dead after 300000ms
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m End 0a126e6d-3057-45d9-89dd-e84e65fa3d40::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [32m[Event Logged][0m - sent_chat
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Start b02dcfba-ef37-4951-82d4-f3e92942a566::generic-openai:gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached websocket plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached chat-history plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attaching user and default agent to Agent cluster.
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m MCP Servers already running, skipping boot.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached rag-memory plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached document-summarizer plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached web-scraping plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached asset-price (asset-price) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached smart-web-reader (smart-web-reader) imported plugin to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":7,"result":{"tools":[{"name":"fetch","description":"Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.","inputSchema":{"description":"Parameters for fetching a URL.","properties":{"url":{"description":"URL to fetch","format":"uri","minLength":1,"title":"Url","type":"string"},"max_length":{"default":5000,"description":"Maximum number of characters to return.","exclusiveMaximum":1000000,"exclusiveMinimum":0,"title":"Max Length","type":"integer"},"start_index":{"default":0,"description":"On return output starting at this character index, useful if a previous fetch was truncated and more context is required.","minimum":0,"title":"Start Index","type":"integer"},"raw":{"default":false,"description":"Get the actual HTML content of the requested page, without simplification.","title":"Raw","type":"boolean"}},"required":["url"],"title":"Fetch","type":"object"}}]}}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Attached MCP::fetch:fetch MCP tool to Agent cluster
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `rag-memory` tool {
  "action": "search",
  "content": "crypto museums or Bitcoin-related physical locations near Denver, Colorado"
}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiEmbedder][0m Initialized bge-m3-q8_0 {"baseURL":"http://anyloom-embedding:8080/v1","maxConcurrentChunks":500,"embeddingMaxChunkLength":2500}
[36m[backend][0m [32minfo[39m: [36m[GenericOpenAiLLM][0m Inference API: http://anyloom-llm:8080/v1 Model: gpt-4
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call rag-memory again because an exact duplicate of previous run of rag-memory.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [DEBUG] Provider supports agent streaming - will use async execution!
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Valid tool call found - running fetch-fetch.
[36m[backend][0m [32minfo[39m: [36m[Deduplicator][0m Starting cooldown for fetch-fetch for 30000ms
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m [debug]: @agent is attempting to call `fetch-fetch` tool {
  "url": "https://tavily.com",
  "max_length": 5000
}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m Executing MCP server: fetch:fetch with args: {"url":"https://tavily.com","max_length":5000}
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected end of JSON input
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected token a in JSON at position 0
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected end of JSON input
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected token p in JSON at position 2
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected token r in JSON at position 2
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected end of JSON input
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport error: SyntaxError: Unexpected token o in JSON at position 1
    at JSON.parse (<anonymous>)
    at deserializeMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:32:55)
    at ReadBuffer.readMessage (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/shared/stdio.js:24:16)
    at StdioClientTransport.processReadBuffer (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:141:50)
    at Socket.<anonymous> (/app/server/node_modules/@modelcontextprotocol/sdk/dist/cjs/client/stdio.js:103:22)
    at Socket.emit (node:events:517:28)
    at addChunk (node:internal/streams/readable:368:12)
    at readableAddChunk (node:internal/streams/readable:341:9)
    at Readable.push (node:internal/streams/readable:278:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)
[36m[backend][0m [32minfo[39m: [36m[MCPHypervisor][0m fetch - Transport message: {"jsonrpc":"2.0","id":8,"result":{"content":[{"type":"text","text":"Contents of https://tavily.com/:\n![](/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F5tlb0lxv%2Fproduction%2F49a9b081b6c696977c112781c322aa1af700b435-3270x2000.png%3Frect%3D0%2C0%2C3270%2C1483%26w%3D1600&w=3840&q=75)\n\nReal-time search, extraction, research, and web crawling through a single, secure API.\n\nTrusted by 1M+ developers around the world\n\n![WRITER](https://cdn.sanity.io/images/5tlb0lxv/production/a6aa3b4863c0bf12915aa7b3b545e2d35ae1b371-111x36.svg?h=70)\n\n![MongoDB](https://cdn.sanity.io/images/5tlb0lxv/production/16ff2c3504d94e5df8c89eb17c3db0734d67d98a-139x35.svg?h=70)\n\n![GROQ](https://cdn.sanity.io/images/5tlb0lxv/production/b0b62d4d994f6474729aa04f03cc6adb952a02f9-96x35.svg?h=70)\n\n![LangChain](https://cdn.sanity.io/images/5tlb0lxv/production/bea27741366f21b42e85f28ba6e11f21b5747b4f-206x35.svg?h=70)\n\n![Monday](https://cdn.sanity.io/images/5tlb0lxv/production/fbfe747f3d3d8e4ab219b92ec04fd7f385a7f0a8-194x35.svg?h=70)\n\n![Cohere](https://cdn.sanity.io/images/5tlb0lxv/production/bca4f8f474015310d9e93ae7e902ece0761a3191-516x108.png?h=70)\n\n![Melio](https://cdn.sanity.io/images/5tlb0lxv/production/bb217d9e5f023791aa18b7aad08f5f3e01683673-92x35.svg?h=70)\n\n![JetBrains](https://cdn.sanity.io/images/5tlb0lxv/production/a2c41b1b27ac117e4e42327eb64ff35b42d240ae-164x35.svg?h=70)\n\n![AWS](https://cdn.sanity.io/images/5tlb0lxv/production/9177596d793b26d549174af03474d5baf630ea01-59x35.svg?h=70)\n\n![Ironclad](https://cdn.sanity.io/images/5tlb0lxv/production/5d0f82653aecbc78852d0ff5d59a46e8c3c37fa6-186x35.svg?h=70)\n\n![IBM](https://cdn.sanity.io/images/5tlb0lxv/production/1198f02ebfa2ea912b7fb62ba1502cf312a4f96b-95x35.svg?h=70)\n\n![BCG](https://cdn.sanity.io/images/5tlb0lxv/production/33d79d4f5d086bc319dc56ec062d521fee870f32-1024x432.svg?h=70)\n\n![Ground models with fresh web context](https://cdn.sanity.io/images/5tlb0lxv/production/830c0f3bf82e41c4521abd7fa0357c26330c0d6d-2006x1844.png?rect=81,0,1844,1844&w=60&h=60)\n\n### Ground models with fresh web context\n\nRetrieve live web data, extract relevant content, and return it structured and chunked for models, so agents reason over facts without hallucinating.\n\n![Handle thousands of web queries in seconds](https://cdn.sanity.io/images/5tlb0lxv/production/da9054cf32d9699107bbc60fbf492bd7d6e2901c-2100x1838.png?rect=131,0,1838,1838&w=60&h=60)\n\n### Handle thousands of web queries in seconds\n\nA production-grade retrieval stack with real-time search, intelligent caching, and indexing keeps latency predictable as traffic grows.\n\n![Ship to production with built-in safeguards](https://cdn.sanity.io/images/5tlb0lxv/production/58114a8d3b4ac8a2323714f65645271dc883c385-1553x1569.png?rect=0,9,1553,1553&w=60&h=60)\n\n### Ship to production with built-in safeguards\n\nRequests pass through security, privacy, and content validation layers that block PII leakage, prompt injection, and malicious sources.\n\n100M+\n\nmonthly requests handled\n\n99.99% uptime\n\nSLA powering mission-critical systems\n\n180 ms\n\np50 on Tavily /search making us fastest on the market\n\n1M+\n\ndevelopers using Tavily\n\nBillions\n\nof pages crawled and extracted without downtime\n\nDrop-in integration\n\nwith leading LLM providers (OpenAI, Anthropic, Groq)\n\n[![Databricks Partners with Tavily on MCP Marketplace](/_next/image?url=%2Fspotlight-placeholders%2Fdatabricks-red.png&w=3840&q=75)](https://www.databricks.com/blog/accelerate-ai-development-databricks-discover-govern-and-build-mcp-and-agent-bricks)[![IBM Partners with Tavily on WatsonX Platform](/spotlight-placeholders/ibm.svg)](https://www.ibm.com/new/announcements/driving-smarter-data-enrichment-ibm-and-tavily-partner-for-agentic-ai-solutions)[![JetBrains Integrates Tavily for Real-Time AI Search](/_next/image?url=%2Fspotlight-placeholders%2FJetBrains.png&w=3840&q=75)](https://www.tavily.com/blog/jetbrains-tavily)[![Tavily releases /research endpoint, achieves state-of-the-art](/_next/image?url=%2Fspotlight-placeholders%2Fresearch.png&w=3840&q=75)](https://chat-research.tavily.com/)[![Tavily raises $25M Series A Funding](/_next/image?url=%2Fspotlight-placeholders%2FSeries%20A.png&w=3840&q=75)](https://techcrunch.com/2025/08/06/tavily-raises-25m-to-connect-ai-agents-to-the-web/)\n\n### Databricks Partners with Tavily on MCP Marketplace\n\n### IBM Partners with Tavily on WatsonX Platform\n\n### JetBrains Integrates Tavily for Real-Time AI Search\n\n### Tavily releases /research endpoint, achieves state-of-the-art\n\n### Tavily raises $25M Series A Funding"}],"isError":false}}
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m MCP server: fetch:fetch completed successfully {"content":[{"type":"text","text":"Contents of https://tavily.com/:\n![](/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F5tlb0lxv%2Fproduction%2F49a9b081b6c696977c112781c322aa1af700b435-3270x2000.png%3Frect%3D0%2C0%2C3270%2C1483%26w%3D1600&w=3840&q=75)\n\nReal-time search, extraction, research, and web crawling through a single, secure API.\n\nTrusted by 1M+ developers around the world\n\n![WRITER](https://cdn.sanity.io/images/5tlb0lxv/production/a6aa3b4863c0bf12915aa7b3b545e2d35ae1b371-111x36.svg?h=70)\n\n![MongoDB](https://cdn.sanity.io/images/5tlb0lxv/production/16ff2c3504d94e5df8c89eb17c3db0734d67d98a-139x35.svg?h=70)\n\n![GROQ](https://cdn.sanity.io/images/5tlb0lxv/production/b0b62d4d994f6474729aa04f03cc6adb952a02f9-96x35.svg?h=70)\n\n![LangChain](https://cdn.sanity.io/images/5tlb0lxv/production/bea27741366f21b42e85f28ba6e11f21b5747b4f-206x35.svg?h=70)\n\n![Monday](https://cdn.sanity.io/images/5tlb0lxv/production/fbfe747f3d3d8e4ab219b92ec04fd7f385a7f0a8-194x35.svg?h=70)\n\n![Cohere](https://cdn.sanity.io/images/5tlb0lxv/production/bca4f8f474015310d9e93ae7e902ece0761a3191-516x108.png?h=70)\n\n![Melio](https://cdn.sanity.io/images/5tlb0lxv/production/bb217d9e5f023791aa18b7aad08f5f3e01683673-92x35.svg?h=70)\n\n![JetBrains](https://cdn.sanity.io/images/5tlb0lxv/production/a2c41b1b27ac117e4e42327eb64ff35b42d240ae-164x35.svg?h=70)\n\n![AWS](https://cdn.sanity.io/images/5tlb0lxv/production/9177596d793b26d549174af03474d5baf630ea01-59x35.svg?h=70)\n\n![Ironclad](https://cdn.sanity.io/images/5tlb0lxv/production/5d0f82653aecbc78852d0ff5d59a46e8c3c37fa6-186x35.svg?h=70)\n\n![IBM](https://cdn.sanity.io/images/5tlb0lxv/production/1198f02ebfa2ea912b7fb62ba1502cf312a4f96b-95x35.svg?h=70)\n\n![BCG](https://cdn.sanity.io/images/5tlb0lxv/production/33d79d4f5d086bc319dc56ec062d521fee870f32-1024x432.svg?h=70)\n\n![Ground models with fresh web context](https://cdn.sanity.io/images/5tlb0lxv/production/830c0f3bf82e41c4521abd7fa0357c26330c0d6d-2006x1844.png?rect=81,0,1844,1844&w=60&h=60)\n\n### Ground models with fresh web context\n\nRetrieve live web data, extract relevant content, and return it structured and chunked for models, so agents reason over facts without hallucinating.\n\n![Handle thousands of web queries in seconds](https://cdn.sanity.io/images/5tlb0lxv/production/da9054cf32d9699107bbc60fbf492bd7d6e2901c-2100x1838.png?rect=131,0,1838,1838&w=60&h=60)\n\n### Handle thousands of web queries in seconds\n\nA production-grade retrieval stack with real-time search, intelligent caching, and indexing keeps latency predictable as traffic grows.\n\n![Ship to production with built-in safeguards](https://cdn.sanity.io/images/5tlb0lxv/production/58114a8d3b4ac8a2323714f65645271dc883c385-1553x1569.png?rect=0,9,1553,1553&w=60&h=60)\n\n### Ship to production with built-in safeguards\n\nRequests pass through security, privacy, and content validation layers that block PII leakage, prompt injection, and malicious sources.\n\n100M+\n\nmonthly requests handled\n\n99.99% uptime\n\nSLA powering mission-critical systems\n\n180 ms\n\np50 on Tavily /search making us fastest on the market\n\n1M+\n\ndevelopers using Tavily\n\nBillions\n\nof pages crawled and extracted without downtime\n\nDrop-in integration\n\nwith leading LLM providers (OpenAI, Anthropic, Groq)\n\n[![Databricks Partners with Tavily on MCP Marketplace](/_next/image?url=%2Fspotlight-placeholders%2Fdatabricks-red.png&w=3840&q=75)](https://www.databricks.com/blog/accelerate-ai-development-databricks-discover-govern-and-build-mcp-and-agent-bricks)[![IBM Partners with Tavily on WatsonX Platform](/spotlight-placeholders/ibm.svg)](https://www.ibm.com/new/announcements/driving-smarter-data-enrichment-ibm-and-tavily-partner-for-agentic-ai-solutions)[![JetBrains Integrates Tavily for Real-Time AI Search](/_next/image?url=%2Fspotlight-placeholders%2FJetBrains.png&w=3840&q=75)](https://www.tavily.com/blog/jetbrains-tavily)[![Tavily releases /research endpoint, achieves state-of-the-art](/_next/image?url=%2Fspotlight-placeholders%2Fresearch.png&w=3840&q=75)](https://chat-research.tavily.com/)[![Tavily raises $25M Series A Funding](/_next/image?url=%2Fspotlight-placeholders%2FSeries%20A.png&w=3840&q=75)](https://techcrunch.com/2025/08/06/tavily-raises-25m-to-connect-ai-agents-to-the-web/)\n\n### Databricks Partners with Tavily on MCP Marketplace\n\n### IBM Partners with Tavily on WatsonX Platform\n\n### JetBrains Integrates Tavily for Real-Time AI Search\n\n### Tavily releases /research endpoint, achieves state-of-the-art\n\n### Tavily raises $25M Series A Funding"}],"isError":false}
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Untooled.stream - will process this chat completion.
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Cannot call fetch-fetch again because the function is on cooldown for fetch-fetch..
[36m[backend][0m [32minfo[39m: [36m[AgentLLM - gpt-4][0m Will assume chat completion without tool call inputs.
[36m[backend][0m [32minfo[39m: Client took too long to respond, chat thread is dead after 300000ms
[36m[backend][0m [32minfo[39m: [36m[AgentHandler][0m End b02dcfba-ef37-4951-82d4-f3e92942a566::generic-openai:gpt-4
