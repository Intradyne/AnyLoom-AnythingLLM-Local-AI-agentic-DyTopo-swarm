{
	"nodes":[
		{"id":"anythingllm","type":"text","text":"## AnythingLLM\n\nUser interface + working memory\nText / Voice to Text / Voice\nBuilt-in web scraper (LLM + manual)\nAuto-loads Qdrant RAG (port 6333)\nWorkspace: `AnyLoom` (auto-configured)\n\n**Agent Skills:** asset-price, smart-web-reader\n**MCP:** fetch, memory, tavily, context7, filesystem, sequential-thinking","x":-200,"y":-720,"width":340,"height":328,"color":"4"},
		{"id":"user_input","type":"text","text":"## User Input\n\nText or voice query\nObsidian notes, to-dos\nFile / web / automation requests","x":-180,"y":-960,"width":280,"height":160,"color":"1"},
		{"id":"obsidian","type":"text","text":"## Obsidian\n\nPersonal knowledge base\nNotes, to-dos, project planning\nCanvas visualizations","x":280,"y":-960,"width":280,"height":160,"color":"6"},
		{"id":"qdrant","type":"text","text":"## Qdrant ‚Äî Port 6333\n\nSingle hybrid instance (dense+sparse RAG)\nServes both AnythingLLM and MCP server\nBGE-M3 via ONNX INT8 on CPU (MCP RAG)\nDense 1024-dim + sparse lexical (RRF fusion)\n~0.6 GB RAM, 0 VRAM\n\nContainer: anyloom-qdrant (Docker Compose)","x":-780,"y":-585,"width":360,"height":285,"color":"5"},
		{"id":"embedding","type":"text","text":"## llama.cpp Embedding\n\nBGE-M3 Q8_0 GGUF (GPU, AnythingLLM)\nPort 8009 (host) / 8080 (container)\nOpenAI-compatible: /v1/embeddings\n1024-dim dense vectors, 8192 ctx/slot\n~605 MB model, ~635 MB VRAM\n2 parallel slots\n\nContainer: anyloom-embedding","x":-780,"y":-940,"width":360,"height":280,"color":"4"},
		{"id":"fc996cdf5d02ea4a","type":"text","text":"Dashboard\n\ngraph view\nmodel manager (with settings)\nfile manager +rag gen\nskill manager +gen\nMCP manager ","x":-1644,"y":-707,"width":284,"height":227},
		{"id":"agent_skills","type":"text","text":"## Agent Skills (Custom)\n\nRun inside AnythingLLM container\nLLM selects tool via function calling\n\n**asset-price** ‚Äî yahoo-finance2 v3\nStocks, crypto, commodities, indices, ETFs\nAlias table + search fallback\n\n**smart-web-reader** ‚Äî 3-tier extraction\nDefuddle ‚Üí Readability+Turndown ‚Üí regex\n8K char truncation, 15s timeout\n\nüìç [skills/](../skills/)","x":640,"y":-852,"width":310,"height":432,"color":"2"},
		{"id":"mcp_server","type":"text","text":"## MCP Server (qdrant-rag)\n\n`src/qdrant_mcp_server.py` (~1,030 lines)\nFastMCP, stdio JSON-RPC transport\n\n**RAG tools (5):** rag_search, rag_status,\nrag_reindex, rag_sources, rag_file_info\n\n**DyTopo tools (3):** swarm_start,\nswarm_status, swarm_result\n\nBGE-M3 ONNX INT8 on CPU (~0.6 GB RAM)\nHybrid dense+sparse search with RRF","x":-200,"y":-15,"width":340,"height":365,"color":"4"},
		{"id":"lm_studio","type":"text","text":"## llama.cpp\n\nInference backend (Docker)\nPort 8008 (host) / 8080 (container)\nOpenAI-compatible: /v1/chat/completions\nGPU-accelerated with 131K context\nModel: Qwen3-30B-A3B Q4_K_M\nParallel slots: 2\n","x":-200,"y":-327,"width":340,"height":257,"color":"4"},
		{"id":"8a45810e2796ae10","type":"text","text":"api calls","x":679,"y":-327,"width":116,"height":50},
		{"id":"n8n","type":"text","text":"## n8n Docker Container\n\nScheduled tasks\nComplex automation\nWorkflows\nn8n can call LLMs or other AI\nAlso has its own Docker MCP server","x":306,"y":-422,"width":284,"height":240,"color":"5"},
		{"id":"docker_mcp","type":"text","text":"## llama.cpp Agent MCP\n\nMCP tools available to the llama.cpp\ninference backend via stdio:\n\n**qdrant-rag (8 tools):**\nrag_search, rag_status, rag_reindex,\nrag_sources, rag_file_info,\nswarm_start, swarm_status, swarm_result\n\n**system-status (6 tools):**\nservice_health, qdrant_collections,\ngpu_status, llm_slots,\ndocker_status, stack_config\n\nüìç [qdrant_mcp_server.py](../src/qdrant_mcp_server.py)\nüìç [system_status_mcp.py](../src/mcp_servers/system_status_mcp.py)","x":255,"y":-158,"width":385,"height":420,"color":"5"},
		{"id":"standalone","type":"text","text":"## Standalone Tools\n\nResponsive bots\nPython smart web scraper\n2D / video / 3D generation models","x":737,"y":-33,"width":243,"height":170,"color":"2"},
		{"id":"dytopo","type":"text","text":"## DyTopo Swarm\n\n`src/dytopo/` ‚Äî 8 core modules + 6 sub-packages\nAsync parallel orchestration (asyncio.gather)\nSemaphore-controlled concurrency (2 slots)\nSemantic routing: MiniLM-L6-v2, cosine sim, threshold œÑ\nTopological tiers for parallel-within-tier execution\nDomains: code ¬∑ math ¬∑ general\nAegean consensus termination\nPost-run memory persistence\nPre-run health checks\n\nSee [swarm-overview.canvas](swarm-overview.canvas) for module details","x":-680,"y":168,"width":360,"height":449,"color":"3"},
		{"id":"rag_sources","type":"text","text":"## RAG Document Sources\n\n**Multi-source indexing ‚Üí Qdrant 6333:**\n6 docs in `rag-docs/`\n- anythingllm/ (6 docs)\nHybrid dense+sparse indexing\nSHA-256 content-hash dedup\nsource_dir payload filtering","x":-840,"y":-127,"width":340,"height":247,"color":"6"},
		{"id":"system_status","type":"text","text":"## System Status MCP\n\nFastMCP server for stack monitoring\n6 tools: service_health, qdrant_collections,\ngpu_status, llm_slots, docker_status, stack_config\nReturns structured JSON health\nUsed by DyTopo preflight checks\n\nüìç [system_status_mcp.py](../src/mcp_servers/system_status_mcp.py)","x":-1200,"y":242,"width":340,"height":300,"color":"6"},
		{"id":"health_monitor","type":"text","text":"## Health Monitor Sidecar\n\nStandalone Python process (no LLM)\nDeterministic health checks every 30s\nAuto-restart via docker restart\nCrash window tracking (3 attempts/15min)\nJSONL structured logging\n\nüìç [health_monitor.py](../scripts/health_monitor.py)","x":-1200,"y":-155,"width":340,"height":275,"color":"1"}
	],
	"edges":[
		{"id":"e1","fromNode":"user_input","fromSide":"bottom","toNode":"anythingllm","toSide":"top","color":"1","label":"chat / query"},
		{"id":"e2","fromNode":"user_input","fromSide":"right","toNode":"obsidian","toSide":"left","color":"1","label":"notes"},
		{"id":"e3","fromNode":"anythingllm","fromSide":"bottom","toNode":"lm_studio","toSide":"top","color":"4","label":"LLM inference"},
		{"id":"e4","fromNode":"anythingllm","fromSide":"left","toNode":"qdrant","toSide":"right","color":"4","label":"hybrid RAG"},
		{"id":"e5","fromNode":"lm_studio","fromSide":"bottom","toNode":"mcp_server","toSide":"top","color":"4","label":"MCP tools"},
		{"id":"e8","fromNode":"mcp_server","fromSide":"left","toNode":"qdrant","toSide":"right","color":"5","label":"search"},
		{"id":"e9","fromNode":"mcp_server","fromSide":"bottom","toNode":"dytopo","toSide":"right","color":"3","label":"swarm tasks"},
		{"id":"e11","fromNode":"rag_sources","fromSide":"top","toNode":"qdrant","toSide":"bottom","color":"6"},
		{"id":"e12","fromNode":"docker_mcp","fromSide":"right","toNode":"standalone","toSide":"left"},
		{"id":"e15","fromNode":"obsidian","fromSide":"bottom","toNode":"anythingllm","toSide":"top","color":"6","label":"context"},
		{"id":"e16","fromNode":"dytopo","fromSide":"top","toNode":"lm_studio","toSide":"left","color":"3","label":"LLM calls"},
		{"id":"b1352f454ef94003","fromNode":"n8n","fromSide":"left","toNode":"anythingllm","toSide":"right","color":"1","label":"chat/query"},
		{"id":"ff8262542ace6b7a","fromNode":"n8n","fromSide":"left","toNode":"lm_studio","toSide":"right","color":"1","label":"chat/query"},
		{"id":"36d3a83a99ed569e","fromNode":"lm_studio","fromSide":"right","toNode":"docker_mcp","toSide":"left","color":"4"},
		{"id":"35c1b2400e8af29d","fromNode":"n8n","fromSide":"right","toNode":"8a45810e2796ae10","toSide":"left"},
		{"id":"79a5b601d269adb7","fromNode":"8a45810e2796ae10","fromSide":"left","toNode":"n8n","toSide":"right"},
		{"id":"9166f6f1838afc97","fromNode":"n8n","fromSide":"right","toNode":"standalone","toSide":"left"},
		{"id":"a85278928ec47069","fromNode":"docker_mcp","fromSide":"top","toNode":"n8n","toSide":"bottom","color":"5"},
		{"id":"e_allm_embed","fromNode":"anythingllm","fromSide":"left","toNode":"embedding","toSide":"right","color":"4","label":"embed chunks"},
		{"id":"e_embed_qdrant","fromNode":"embedding","fromSide":"bottom","toNode":"qdrant","toSide":"top","color":"4","label":"embeddings"},
		{"id":"e_allm_skills","fromNode":"anythingllm","fromSide":"right","toNode":"agent_skills","toSide":"left","color":"2","label":"@agent tools"},
		{"id":"e_status_dytopo","fromNode":"system_status","fromSide":"right","toNode":"dytopo","toSide":"left","color":"6","label":"diagnostics"},
		{"id":"e_hm_llm","fromNode":"health_monitor","fromSide":"top","toNode":"lm_studio","toSide":"left","color":"1","label":"monitors"},
		{"id":"e_hm_qdrant","fromNode":"health_monitor","fromSide":"top","toNode":"qdrant","toSide":"left","color":"1","label":"monitors"},
		{"id":"e_hm_embed","fromNode":"health_monitor","fromSide":"top","toNode":"embedding","toSide":"left","color":"1","label":"monitors"}
	]
}